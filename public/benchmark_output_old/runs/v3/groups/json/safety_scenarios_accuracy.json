{
  "title": "Accuracy",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "Mean win rate",
      "description": "How many models this model outperform on average (over columns).",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {}
    },
    {
      "value": "HarmBench - HarmBench - Model Evaluated Safety score",
      "description": "HarmBench\n\nHarmBench - Model Evaluated Safety score: HarmBench - Model Evaluated Safety score",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "HarmBench - Model Evaluated Safety score",
        "run_group": "HarmBench"
      }
    },
    {
      "value": "SimpleSafetyTests - SimpleSafetyTests - Model Evaluated Safety score",
      "description": "SimpleSafetyTests\n\nSimpleSafetyTests - Model Evaluated Safety score: SimpleSafetyTests - Model Evaluated Safety score",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "SimpleSafetyTests - Model Evaluated Safety score",
        "run_group": "SimpleSafetyTests"
      }
    },
    {
      "value": "BBQ - BBQ accuracy",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\nBBQ accuracy: BBQ accuracy",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "BBQ accuracy",
        "run_group": "BBQ"
      }
    },
    {
      "value": "Anthropic Red Team - Anthropic Red Team - Model Evaluated Safety score",
      "description": "Anthropic Red Team\n\nAnthropic Red Team - Model Evaluated Safety score: Anthropic Red Team - Model Evaluated Safety score",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "Anthropic Red Team - Model Evaluated Safety score",
        "run_group": "Anthropic Red Team"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "Llama 3 (70B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.0,
        "markdown": false
      },
      {
        "value": 0.125,
        "description": "min=0.125, mean=0.125, max=0.125, sum=0.125 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=meta_llama-3-70b"
        ]
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=meta_llama-3-70b"
        ]
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=meta_llama-3-70b"
        ]
      },
      {
        "value": 0.875,
        "description": "min=0.875, mean=0.875, max=0.875, sum=0.875 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=meta_llama-3-70b"
        ]
      }
    ],
    [
      {
        "value": "Llama 3 (8B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.1875,
        "markdown": false
      },
      {
        "value": 0.125,
        "description": "min=0.125, mean=0.125, max=0.125, sum=0.125 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=meta_llama-3-8b"
        ]
      },
      {
        "value": 0.375,
        "description": "min=0.375, mean=0.375, max=0.375, sum=0.375 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=meta_llama-3-8b"
        ]
      },
      {
        "value": 0.5,
        "description": "min=0.5, mean=0.5, max=0.5, sum=0.5 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=meta_llama-3-8b"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=meta_llama-3-8b"
        ]
      }
    ],
    [
      {
        "value": "Mixtral (8x22B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.25,
        "markdown": false
      },
      {
        "value": 0.5,
        "description": "min=0.5, mean=0.5, max=0.5, sum=0.5 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=mistralai_mixtral-8x22b"
        ]
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=mistralai_mixtral-8x22b"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=mistralai_mixtral-8x22b"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=mistralai_mixtral-8x22b"
        ]
      }
    ],
    [
      {
        "value": "Qwen2 Instruct (72B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.4375,
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=qwen_qwen2-72b-instruct"
        ]
      },
      {
        "value": 0.875,
        "description": "min=0.875, mean=0.875, max=0.875, sum=0.875 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=qwen_qwen2-72b-instruct"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=qwen_qwen2-72b-instruct"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=qwen_qwen2-72b-instruct"
        ]
      }
    ],
    [
      {
        "value": "Claude 3 Opus (20240229)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.59375,
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=anthropic_claude-3-opus-20240229"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=anthropic_claude-3-opus-20240229"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=anthropic_claude-3-opus-20240229"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=anthropic_claude-3-opus-20240229"
        ]
      }
    ],
    [
      {
        "value": "Claude 3.5 Sonnet (20240620)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.71875,
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=anthropic_claude-3-5-sonnet-20240620"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=anthropic_claude-3-5-sonnet-20240620"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=anthropic_claude-3-5-sonnet-20240620"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=anthropic_claude-3-5-sonnet-20240620"
        ]
      }
    ],
    [
      {
        "value": "Gemini 1.5 Pro (001)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.5625,
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=google_gemini-1.5-pro-001"
        ]
      },
      {
        "value": 0.875,
        "description": "min=0.875, mean=0.875, max=0.875, sum=0.875 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=google_gemini-1.5-pro-001"
        ]
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=google_gemini-1.5-pro-001"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=google_gemini-1.5-pro-001"
        ]
      }
    ],
    [
      {
        "value": "GPT-4 Turbo (2024-04-09)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.90625,
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=openai_gpt-4-turbo-2024-04-09"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=openai_gpt-4-turbo-2024-04-09"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=openai_gpt-4-turbo-2024-04-09"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=openai_gpt-4-turbo-2024-04-09"
        ]
      }
    ],
    [
      {
        "value": "GPT-4o (2024-05-13)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.84375,
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "harm_bench:model=openai_gpt-4o-2024-05-13"
        ]
      },
      {
        "value": 0.75,
        "description": "min=0.75, mean=0.75, max=0.75, sum=0.75 (1)",
        "style": {},
        "markdown": false,
        "run_spec_names": [
          "simple_safety_tests:model=openai_gpt-4o-2024-05-13"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "bbq:subject=all,method=multiple_choice_joint,model=openai_gpt-4o-2024-05-13"
        ]
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false,
        "run_spec_names": [
          "anthropic_red_team:model=openai_gpt-4o-2024-05-13"
        ]
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "benchmark_output/runs/v3/groups/latex/safety_scenarios_accuracy.tex"
    },
    {
      "text": "JSON",
      "href": "benchmark_output/runs/v3/groups/json/safety_scenarios_accuracy.json"
    }
  ],
  "name": "accuracy"
}