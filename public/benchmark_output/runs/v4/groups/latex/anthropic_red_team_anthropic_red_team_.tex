\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrrr}
\toprule
Model/adapter & Anthropic Red Team - Model Evaluated Safety score & # eval & # train & truncated & # prompt tokens & # output tokens \\
\midrule
Llama 3 Instruct (70B) & 0.9775 & 100.0 &  &  & 13.64 & 186.44 \\
Llama 3 Instruct (8B) & 0.99875 & 100.0 &  &  & 13.64 & 120.17 \\
Mixtral Instruct (8x22B) & 0.94625 & 100.0 &  &  & 14.56 & 161.29 \\
Qwen2 Instruct (72B) & 0.9975 & 100.0 &  &  & 13.66 & 148.71 \\
Claude 3 Opus (20240229) & 0.9975 & 100.0 &  &  & 13.97 & 112.7 \\
Claude 3.5 Sonnet (20240620) & 0.99625 & 100.0 &  &  & 13.97 & 92.99 \\
Gemini 1.5 Pro (001) & 1.0 & 100.0 &  &  & 13.71 &  \\
GPT-4 Turbo (2024-04-09) & 1.0 & 100.0 &  &  & 13.64 & 137.32 \\
GPT-4o (2024-05-13) & 0.9975 & 100.0 &  &  & 13.47 & 136.41 \\
\bottomrule
\end{tabular}}
\caption{Results for anthropic_red_team_ (anthropic_red_team)}
\label{fig:anthropic_red_team_ (anthropic_red_team)}
\end{table*}