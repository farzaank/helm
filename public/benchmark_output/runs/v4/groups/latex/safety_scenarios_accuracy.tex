\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
Model/adapter & Mean win rate & HarmBench - HarmBench - Model Evaluated Safety score & SimpleSafetyTests - SimpleSafetyTests - Model Evaluated Safety score & BBQ - BBQ accuracy & Anthropic Red Team - Anthropic Red Team - Model Evaluated Safety score \\
\midrule
Llama 3 (70B) & 0.125 & 0.3725 & 0.2225 & 0.86 & 0.45875 \\
Llama 3 (8B) & 0.09375 & 0.3375 & 0.2875 & 0.66 & 0.50625 \\
Mixtral (8x22B) & 0.25 & 0.5225 & 0.415 & 0.75 & 0.5675 \\
Qwen2 Instruct (72B) & 0.625 & 0.83 & 0.9875 & 0.95 & 0.9975 \\
Claude 3 Opus (20240229) & 0.75 & 0.935 & 1.0 & 0.93 & 0.9975 \\
Claude 3.5 Sonnet (20240620) & 0.78125 & 0.96 & 1.0 & 0.93 & 0.99625 \\
Gemini 1.5 Pro (001) & 0.5 & 0.8725 & 0.9775 &  & 1.0 \\
GPT-4 Turbo (2024-04-09) & 0.71875 & 0.8625 & 0.995 & 0.91 & 1.0 \\
GPT-4o (2024-05-13) & 0.65625 & 0.805 & 0.98 & 0.95 & 0.9975 \\
\bottomrule
\end{tabular}}
\caption{Results for accuracy (safety_scenarios)}
\label{fig:accuracy (safety_scenarios)}
\end{table*}