\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
Model/adapter & Mean win rate & HarmBench - HarmBench - Model Evaluated Safety score & SimpleSafetyTests - SimpleSafetyTests - Model Evaluated Safety score & BBQ - BBQ accuracy & Anthropic Red Team - Anthropic Red Team - Model Evaluated Safety score \\
\midrule
Llama 3 (70B) & 0.11363636363636365 & 0.3725 & 0.2225 & 0.86 & 0.45875 \\
Llama 3 Instruct (70B) & 0.38636363636363635 & 0.7125 & 1.0 & 0.29 & 0.9775 \\
Llama 3 (8B) & 0.06818181818181818 & 0.3375 & 0.2875 & 0.66 & 0.50625 \\
Llama 3 Instruct (8B) & 0.5454545454545454 & 0.815 & 0.99 & 0.74 & 0.99875 \\
Mixtral (8x22B) & 0.20454545454545453 & 0.5225 & 0.415 & 0.75 & 0.5675 \\
Mixtral Instruct (8x22B) & 0.3409090909090909 & 0.5775 & 0.9375 & 0.92 & 0.94625 \\
Qwen2 Instruct (72B) & 0.6590909090909091 & 0.83 & 0.9875 & 0.95 & 0.9975 \\
Claude 3 Opus (20240229) & 0.7727272727272727 & 0.935 & 1.0 & 0.93 & 0.9975 \\
Claude 3.5 Sonnet (20240620) & 0.7954545454545454 & 0.96 & 1.0 & 0.93 & 0.99625 \\
Gemini 1.5 Pro (001) & 0.7272727272727273 & 0.8725 & 0.9775 & 0.94 & 1.0 \\
GPT-4 Turbo (2024-04-09) & 0.7272727272727273 & 0.8625 & 0.995 & 0.91 & 1.0 \\
GPT-4o (2024-05-13) & 0.6590909090909091 & 0.805 & 0.98 & 0.95 & 0.9975 \\
\bottomrule
\end{tabular}}
\caption{Results for accuracy (safety_scenarios)}
\label{fig:accuracy (safety_scenarios)}
\end{table*}