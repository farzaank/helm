\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrr}
\toprule
Model/adapter & Mean win rate & BBQ - Observed inference time (s) \\
\midrule
Llama 3 Instruct (70B) & 0.2727272727272727 & 0.4973434925079346 \\
Llama 3 Instruct (8B) & 0.9090909090909091 & 0.32636465787887575 \\
Mixtral Instruct (8x22B) & 0.7272727272727273 & 0.3650758147239685 \\
Qwen2 Instruct (72B) & 1.0 & 0.2833996081352234 \\
Claude 3 Opus (20240229) &  & 1.4926978182792663 \\
Claude 3.5 Sonnet (20240620) & 0.18181818181818182 & 0.6757207655906677 \\
Gemini 1.5 Pro (001) & 0.09090909090909091 & 0.7031311821937561 \\
GPT-3.5 Turbo (0613) & 0.45454545454545453 & 0.400710711479187 \\
GPT-3.5 Turbo (1106) & 0.8181818181818182 & 0.34552908897399903 \\
GPT-3.5 Turbo (0125) & 0.6363636363636364 & 0.38806658029556274 \\
GPT-4 Turbo (2024-04-09) & 0.36363636363636365 & 0.4152229261398315 \\
GPT-4o (2024-05-13) & 0.5454545454545454 & 0.39990686893463134 \\
\bottomrule
\end{tabular}}
\caption{Results for efficiency_detailed (targeted_evaluations)}
\label{fig:efficiency_detailed (targeted_evaluations)}
\end{table*}