{
  "safety_scenarios": {
    "display_name": "Safety Scenarios",
    "description": "Scenarios for the model safety",
    "taxonomy": null
  },
  "harm_bench": {
    "display_name": "HarmBench",
    "description": "HarmBench",
    "taxonomy": {
      "task": "question answering",
      "what": "n/a",
      "when": "n/a",
      "who": "n/a",
      "language": "English"
    }
  },
  "simple_safety_tests": {
    "display_name": "SimpleSafetyTests",
    "description": "SimpleSafetyTests",
    "taxonomy": {
      "task": "question answering",
      "what": "n/a",
      "when": "n/a",
      "who": "n/a",
      "language": "English"
    }
  },
  "bbq": {
    "display_name": "BBQ",
    "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).",
    "taxonomy": {
      "task": "question answering",
      "what": "n/a",
      "when": "n/a",
      "who": "n/a",
      "language": "English"
    }
  },
  "anthropic_red_team": {
    "display_name": "Anthropic Red Team",
    "description": "Anthropic Red Team",
    "taxonomy": {
      "task": "question answering",
      "what": "?",
      "when": "?",
      "who": "?",
      "language": "English"
    }
  }
}