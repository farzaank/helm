\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
Model/adapter & Mean win rate & HarmBench - HarmBench - Model Evaluated Safety score & SimpleSafetyTests - SimpleSafetyTests - Model Evaluated Safety score & BBQ - BBQ accuracy & Anthropic Red Team - Anthropic Red Team - Model Evaluated Safety score \\
\midrule
Llama 3 (70B) &  & 0.125 &  &  & 0.875 \\
Llama 3 (8B) & 0.1875 & 0.125 & 0.375 & 0.5 & 1.0 \\
Mixtral (8x22B) & 0.25 & 0.5 &  & 1.0 & 1.0 \\
Qwen2 Instruct (72B) & 0.4375 & 1.0 & 0.875 & 1.0 & 1.0 \\
Claude 3 Opus (20240229) & 0.59375 & 1.0 & 1.0 & 1.0 & 1.0 \\
Claude 3.5 Sonnet (20240620) & 0.71875 & 1.0 & 1.0 & 1.0 & 1.0 \\
Gemini 1.5 Pro (001) & 0.5625 & 1.0 & 0.875 &  & 1.0 \\
GPT-4 Turbo (2024-04-09) & 0.90625 & 1.0 & 1.0 & 1.0 & 1.0 \\
GPT-4o (2024-05-13) & 0.84375 & 1.0 & 0.75 & 1.0 & 1.0 \\
\bottomrule
\end{tabular}}
\caption{Results for accuracy (safety_scenarios)}
\label{fig:accuracy (safety_scenarios)}
\end{table*}